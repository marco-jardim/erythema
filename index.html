<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Erythema Detection - Skin Inflammation Analysis</title>
    <link rel="icon" type="image/svg+xml" href="assets/favicon.svg">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <nav>
            <h1>üî¨ Erythema Detection Tool</h1>
            <p>Advanced spectral filtering techniques for enhanced erythema detection in darker skin tones</p>
            <div class="nav-links">
                <button class="nav-link" data-modal="erythema">‚ÑπÔ∏è About Erythema</button>
                <button class="nav-link" data-modal="a-star">üß™ a* Channel</button>
                <button class="nav-link" data-modal="erythema-index">üìà Erythema Index</button>
                <button class="nav-link" data-modal="ita">üìè ITA¬∞ Index</button>
                <button class="nav-link" data-modal="rgb-ratio">üåà RGB Ratio</button>
                <button class="nav-link" data-modal="melanin">üåì Melanin Filter</button>
                <button class="nav-link" data-modal="contrast-boost">üîÜ Contrast Boost</button>
                <button class="nav-link" data-modal="hair-reduction">‚úÇÔ∏è Hair Reduction</button>
            </div>

            <div class="tab-switcher" role="tablist" aria-label="Primary sections">
                <button id="tab-workspace" class="tab-switch active" data-tab-target="app" aria-selected="true">üõ†Ô∏è Workspace</button>
                <button id="tab-references" class="tab-switch" data-tab-target="references" aria-selected="false">üìö Scientific Sources</button>
            </div>
        </nav>

        <section id="appPanel" class="tab-panel active" aria-labelledby="tab-workspace">
            <div class="main-content">
            <div class="info-box">
                <p><strong>Note:</strong> Detecting erythema (skin redness/inflammation) in darker skin tones is challenging due to melanin masking. This tool applies various color-space transformations and spectral filters to enhance the visibility of inflammation markers.</p>
            </div>

            <div class="controls-section">
                <div class="control-group">
                    <label>Step 1: Upload or Take a Photo</label>
                    <div class="file-upload-group">
                        <label for="imageUpload" class="file-upload mobile-only">
                            üì∑ Take Photo / üìÅ Choose
                        </label>
                        <label for="imageUpload" class="file-upload desktop-only">
                            üìÅ Upload Image
                        </label>
                        <button type="button" class="file-upload desktop-only" id="cameraStartBtn">üé• Start Desktop Camera</button>
                        <button type="button" class="file-upload desktop-only hidden" id="cameraSnapBtn" disabled>üì∏ Capture Frame</button>
                        <button type="button" class="file-upload desktop-only hidden" id="cameraStopBtn" disabled>üõë Stop Camera</button>
                    </div>
                    <input type="file" id="imageCapture" accept="image/*" capture="environment">
                    <input type="file" id="imageUpload" accept="image/*">
                    <div class="camera-preview desktop-only" id="cameraPreviewWrapper">
                        <video id="cameraPreview" autoplay playsinline></video>
                    </div>
                    <span id="fileName" style="margin-left: 15px; color: #666;"></span>
                </div>

                <div class="control-group crop-group">
                    <label>Optional: Crop a square before processing</label>
                    <div class="crop-inline">
                        <button type="button" class="btn btn-secondary" id="cropBtn" disabled>‚úÇÔ∏è Crop square</button>
                        <span class="helper-text">After the image loads, click to select a square region to use for all filters.</span>
                    </div>
                </div>

                <div class="control-group">
                    <label>Step 2: Early Filters (apply before others)</label>
                    <div class="technique-grid" id="earlyGrid">
                        <div class="technique-item" data-technique="hair-reduction">
                            <div class="order-badge">1</div>
                            <h4>‚úÇÔ∏è Hair Reduction</h4>
                            <p>Mask + inpaint to reduce hair interference</p>
                        </div>
                        <div class="technique-item" data-technique="melanin-filter">
                            <div class="order-badge">2</div>
                            <h4>üåì Melanin Compensation</h4>
                            <p>Reduces melanin masking</p>
                        </div>
                    </div>
                </div>

                <div class="control-group">
                    <label>Step 3: Main Filters (click to select, order matters)</label>
                    <div id="techniqueGrid">
                        <div class="technique-group">
                            <h5>Core / Early (apply first)</h5>
                            <div class="technique-grid">
                                <div class="technique-item" data-technique="a-star">
                                    <div class="order-badge">1</div>
                                    <h4>üß™ a* Channel (Lab)</h4>
                                    <p>Isolates red-green chromaticity</p>
                                </div>
                                <div class="technique-item" data-technique="erythema-index">
                                    <div class="order-badge">2</div>
                                    <h4>üìà Erythema Index (EI)</h4>
                                    <p>Quantifies redness intensity</p>
                                </div>
                                <div class="technique-item" data-technique="ita">
                                    <div class="order-badge">3</div>
                                    <h4>üìè ITA¬∞ (Typology Angle)</h4>
                                    <p>Adjusts for skin brightness</p>
                                </div>
                                <div class="technique-item" data-technique="rgb-ratio">
                                    <div class="order-badge">4</div>
                                    <h4>üåà Spectral Ratio Composite</h4>
                                    <p>G/R, R/G, (B¬∑G)/R pseudo-color (fake multispectral)</p>
                                </div>
                            </div>
                        </div>
                        <div class="technique-group">
                            <h5>Finishing / Late (apply last)</h5>
                            <div class="technique-grid">
                                <div class="technique-item" data-technique="contrast-boost">
                                    <div class="order-badge">5</div>
                                    <h4>üîÜ Contrast Enhancement</h4>
                                    <p>Increases visual clarity</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="control-group">
                    <label>Step 3: Apply Filters</label>
                    <div class="button-group">
                        <button class="btn btn-primary" onclick="applyFilters()">üé® Apply Selected Filters</button>
                        <button class="btn btn-secondary" onclick="resetFilters()">üîÑ Reset</button>
                        <button class="btn btn-secondary" onclick="clearSelection()">‚ùå Clear Selection</button>
                        <button class="btn derm-btn" type="button" id="dermBtn">ü©∫ Derm mode</button>
                        <input type="checkbox" id="dermToggle" style="display:none;">
                    </div>
                </div>
            </div>

            <div class="loading" id="loading">Processing image...</div>

            <div class="canvas-section" id="canvasSection" style="display: none;">
                <div class="canvas-container">
                    <h3>Before / After</h3>
                    <div class="view-toggle">
                        <button id="labViewBtn" class="toggle-btn active" type="button">üß™ Lab</button>
                        <button id="fusedViewBtn" class="toggle-btn" type="button">üî• Fused EI<sub>hb</sub></button>
                    </div>
                    <div class="overlap-wrapper" id="overlapWrapper">
                        <canvas id="processedCanvas"></canvas>
                        <canvas id="originalCanvas"></canvas>
                        <div id="compareSlider" class="slider-handle" aria-label="Reveal processed image"></div>
                    </div>
                    <div class="canvas-actions">
                        <label class="toggle-row">
                            <input type="checkbox" id="labToggle" disabled>
                            <span>Show erythema lab map (a*)</span>
                        </label>
                        <button class="download-btn" onclick="downloadProcessed()">üíæ Download Result</button>
                        <button class="download-btn" onclick="downloadLabMap()">‚¨áÔ∏è Lab Map</button>
                        <button class="download-btn" onclick="downloadConfidenceMask()">‚¨áÔ∏è Confidence Mask</button>
                    </div>
                </div>

                <div class="canvas-container">
                    <h3>Dual View: Lab Map & EI<sub>hb</sub> Heatmap</h3>
                    <div class="dual-grid">
                        <div>
                            <h4 style="margin-bottom:8px;">Lab Map (L<sub>max</sub>‚ÄìL)√óa*</h4>
                            <div class="canvas-wrapper">
                                <canvas id="labPreviewCanvas"></canvas>
                            </div>
                        </div>
                        <div>
                            <h4 style="margin-bottom:8px;">Fused EI<sub>hb</sub> Heatmap</h4>
                            <div class="canvas-wrapper">
                                <canvas id="heatmapPreviewCanvas"></canvas>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="referencesPanel" class="tab-panel" aria-labelledby="tab-references">
            <div class="references-section">
                <div class="cite-box" aria-labelledby="cite-label">
                    <div class="cite-top">
                        <div>
                            <p class="eyebrow" id="cite-label">Cite this page</p>
                            <h4>Copy a ready-to-use reference</h4>
                        </div>
                        <div class="cite-controls">
                            <label for="citationStyle">Style</label>
                            <select id="citationStyle">
                                <option value="abnt">ABNT</option>
                                <option value="apa">APA 7</option>
                                <option value="vancouver">Vancouver</option>
                                <option value="ieee">IEEE</option>
                                <option value="mla">MLA 9</option>
                                <option value="chicago">Chicago (Author‚ÄìDate)</option>
                            </select>
                            <button id="citationCopyBtn" class="btn btn-secondary">üìã Copy</button>
                        </div>
                    </div>
                    <textarea id="citationText" class="cite-text" rows="4" readonly></textarea>
                    <p class="cite-hint">URL updates automatically; citation date is set to 8 Dec 2025.</p>
                </div>

                <div class="reference-grid">
                    <!-- 1. EP2976013A1 ------------------------------------------------------- -->
                    <article id="ref-1-ep2976013a1" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>1. EP2976013A1 ‚Äì Methods for Assessing Erythema</h3>
                                <p class="reference-citation">
                                    Neubauer, A., &amp; Schnidar, H. (2015). <strong>Methods for assessing erythema (EP2976013A1)</strong>. European Patent Office. <a href="https://patents.google.com/patent/EP2976013A1/en" target="_blank" rel="noopener noreferrer">https://patents.google.com/patent/EP2976013A1/en</a>
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge">Patent</span>
                                <a class="pdf-pill" href="https://patents.google.com/patent/EP2976013A1/en" target="_blank" rel="noopener noreferrer">Patent page ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>This European patent describes colourimetric methods for objectively assessing erythema from digital skin images. The inventors propose converting RGB data to the CIELAB colour space and using the red‚Äìgreen opponent dimension (<em>a*</em>) as a primary indicator of erythema. To compensate for baseline pigmentation and illumination, they introduce an erythema index of the form (<em>L<sub>max</sub> ‚Äì L*</em>) √ó <em>a*</em>, where <em>L*</em> is pixel lightness and <em>L<sub>max</sub></em> is the maximum attainable (or image‚Äëspecific) lightness value. Regions that are simultaneously darker and relatively redder are thereby emphasised, improving the contrast of subtle inflammatory changes.</p>
                                <p>In the present erythema filter app, this patent motivates the dedicated ‚ÄúCIELAB Erythema Index‚Äù mode. Uploaded trichoscopy images are transformed to CIELAB, the quantity (<em>L<sub>max</sub> ‚Äì L*</em>) √ó <em>a*</em> is computed per pixel, and the result is mapped either to a greyscale heatmap or to false colours. This follows the patent‚Äôs core idea: neutralise the average skin tone and amplify relative increases in redness, with particular benefit for areas where erythema is partially masked by melanin.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 2. OpenOximetry Skin Color Quantification ---------------------------- -->
                    <article id="ref-2-openoximetry" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>2. Skin Color Quantification ‚Äì OpenOximetry</h3>
                                <p class="reference-citation">
                                    Open Oximetry Project. (2023). <strong>Skin color quantification</strong>. Retrieved December 8, 2025, from <a href="https://openoximetry.org/skin-color-quantification/" target="_blank" rel="noopener noreferrer">https://openoximetry.org/skin-color-quantification/</a>
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-web">Web guide</span>
                                <a class="pdf-pill" href="https://openoximetry.org/skin-color-quantification/" target="_blank" rel="noopener noreferrer">Open online ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>The OpenOximetry ‚ÄúSkin Color Quantification‚Äù resource synthesises current evidence on objective skin pigmentation metrics for optical medical devices. It reviews colour spaces (especially CIELAB), the Individual Typology Angle (ITA¬∞), melanin indices, and visual scales such as the Monk Skin Tone scale, emphasising that race and ethnicity are poor proxies for actual pigmentation. The document highlights how the <em>a*</em> channel can be used as an erythema surrogate, while <em>L*</em> and <em>b*</em> relate more directly to melanin content and tanning.</p>
                                <p>For this app, the OpenOximetry guidelines underpin two design choices: (1) the use of CIELAB and ITA‚Äëstyle metrics instead of Fitzpatrick Skin Type as internal descriptors of baseline pigmentation; and (2) the separation of ‚Äúerythema‚Äëlike‚Äù channels from ‚Äúmelanin‚Äëlike‚Äù channels. In practice, this means that the user interface exposes filters focusing on <em>a*</em> (erythema) and on composite indices inspired by melanin metrics, while explicitly avoiding racial labels. This alignment with medical‚Äëdevice recommendations is intended to support fairer performance across diverse skin tones.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 3. Measuring Human Skin Colour -------------------------------------- -->
                    <article id="ref-3-wang-2015-skin-colour" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>3. Measuring Human Skin Colour</h3>
                                <p class="reference-citation">
                                    Wang, M., Xiao, K., Wuerger, S., Cheung, V., &amp; Luo, M. R. (2015). <strong>Measuring human skin colour</strong>. In <em>Proceedings of the 23rd Color and Imaging Conference</em> (pp. 230‚Äì234). Springfield, VA: Society for Imaging Science and Technology.
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-conf">Conference</span>
                                <a class="pdf-pill" href="assets/articles/measuring-human-skin-colour-2015-wang.pdf" target="_blank" rel="noopener noreferrer">PDF (local) ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>Wang et al. present a large database of CIELAB skin measurements collected from 188 subjects across four ethnic groups, using both a tele‚Äëspectroradiometer and a spectrophotometer at multiple body sites. They evaluate measurement repeatability and reveal systematic differences in colour distribution across locations, instruments, and ethnicities, showing that skin colours cluster in characteristic regions of the <em>L*</em>‚Äì<em>a*</em>‚Äì<em>b*</em> space. Their work also demonstrates the impact of measurement geometry and instrumentation on derived CIELAB values.</p>
                                <p>This database informs the app‚Äôs assumptions about the ‚Äútypical‚Äù range of skin tones in CIELAB space and about how much variation can be expected within a single patient. Thresholds used to normalise <em>a*</em> and to rescale erythema indices are chosen so that, for most human skin colours, the enhanced images remain numerically meaningful and do not saturate. The paper also motivates the option to aggregate over local neighbourhoods rather than relying on single‚Äëpixel values, mirroring the authors‚Äô emphasis on repeatability and spatial averaging in skin colour measurement.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 4. Research Techniques Made Simple: Cutaneous Colorimetry ------------ -->
                    <article id="ref-4-ly-2020-colorimetry" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>4. Research Techniques Made Simple: Cutaneous Colorimetry</h3>
                                <p class="reference-citation">
                                    Ly, B. C. K., et al. (2020). <strong>Research techniques made simple: Cutaneous colorimetry: A reliable technique for objective skin color measurement.</strong> <em>Journal of Investigative Dermatology, 140</em>(1), 3‚Äì12.e1. https://doi.org/10.1016/j.jid.2019.11.003
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-review">Review</span>
                                <a class="pdf-pill" href="assets/articles/cutaneous-colorimetry-ly-2020.pdf" target="_blank" rel="noopener noreferrer">PDF (local) ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>Ly et al. provide a didactic overview of cutaneous colorimetry, explaining how tristimulus colourimeters and spectrophotometers quantify skin colour in the CIELAB space. They discuss the main skin chromophores (melanin, haemoglobin, bilirubin, carotene) and show how <em>L*</em>, <em>a*</em> and <em>b*</em> can be interpreted in dermatology: <em>L*</em> and derived ITA¬∞ as proxies for constitutive pigmentation, <em>a*</em> for erythema, and <em>b*</em> for tanning and carotenoid content. The article also reviews practical aspects such as calibration, measurement geometry and sources of error.</p>
                                <p>In the erythema filter app, this review serves as the conceptual backbone for all CIELAB‚Äëbased processing. The mapping of redness to the <em>a*</em> axis, the use of <em>L*</em> to compensate for baseline pigmentation, and the general idea of treating colour differences as ŒîE* in a perceptually uniform space are directly inspired by the techniques summarised by Ly et al. The documentation and tooltips presented to the user adopt their terminology, helping clinicians interpret enhanced trichoscopy images within a clinically validated colour framework.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 5. Melanometry for objective evaluation of skin pigmentation ---------- -->
                    <article id="ref-5-vasudevan-2024-melanometry" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>5. Melanometry for Objective Evaluation of Skin Pigmentation</h3>
                                <p class="reference-citation">
                                    Vasudevan, S., Vogt, W. C., Weininger, S., &amp; Pfefer, T. J. (2024). <strong>Melanometry for objective evaluation of skin pigmentation in pulse oximetry studies.</strong> <em>Communications Medicine, 4</em>(1), Article 138. https://doi.org/10.1038/s43856-024-00550-7
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-review">Review</span>
                                <a class="pdf-pill" href="assets/articles/melanometry-vasudevan-2024.pdf" target="_blank" rel="noopener noreferrer">PDF (local) ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>This review examines optical melanometry as an objective way to quantify skin pigmentation, particularly for evaluating bias in pulse oximeters. The authors compare melanin metrics derived from colourimeters, narrow‚Äëband spectrophotometers and more advanced spectroscopic approaches, highlighting issues such as repeatability, robustness to confounders (notably blood content) and agreement with histological melanin measurements. They conclude that colourimetry‚Äëbased indices like ITA¬∞ and <em>L*</em> perform better than purely subjective classifications, but also warn that haemoglobin and other chromophores can contaminate melanin estimates if not properly accounted for.</p>
                                <p>In this project, the melanometry literature is used as a cautionary guide. When designing filters to highlight erythema, the app explicitly separates ‚Äúerythema indices‚Äù (based on red‚Äìgreen contrast or <em>a*</em>) from ‚Äúpigmentation descriptors‚Äù (based on <em>L*</em>, ITA‚Äëlike quantities or melanin‚Äëinspired ratios). This separation follows the paper‚Äôs emphasis on avoiding cross‚Äëtalk between melanin and haemoglobin signals. It also motivates the choice to treat any pigmentation‚Äërelated outputs as contextual diagnostics rather than direct measures of melanin concentration.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 6. Racial limitations of Fitzpatrick skin type ------------------------ -->
                    <article id="ref-6-ware-2020-fst-limitations" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>6. Racial Limitations of Fitzpatrick Skin Type</h3>
                                <p class="reference-citation">
                                    Ware, O. R., Dawson, J. E., Shinohara, M. M., &amp; Taylor, S. C. (2020). <strong>Racial limitations of Fitzpatrick skin type.</strong> <em>Cutis, 105</em>(2), 77‚Äì80.
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-critique">Critique</span>
                                <a class="pdf-pill" href="assets/articles/fitzpatrick-limitations-ware-2020.pdf" target="_blank" rel="noopener noreferrer">PDF (local) ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>Ware et al. critique the widespread use of the Fitzpatrick Skin Type (FST) scale as a proxy for race, ethnicity or static skin colour, noting that FST was originally developed to characterise sunburn response in phototherapy rather than constitutive pigmentation. Through a survey of dermatologists and trainees, they document frequent conflation of race and FST and argue that this practice obscures real variation in pigmentation and can reinforce racial essentialism. The article advocates for more culturally appropriate and clinically relevant methods to describe skin of colour, and for renewed emphasis on the original, limited purpose of FST in training.</p>
                                <p>In the erythema filter app, this critique underpins the decision not to use Fitzpatrick types anywhere in the user interface or internal algorithms. Instead, the application relies on direct colourimetric descriptors of the photographed scalp (such as <em>L*</em>, ITA‚Äëlike angles or melanin‚Äëinspired scores) and on patient‚Äëneutral terminology such as ‚Äúbaseline pigmentation‚Äù or ‚Äúdarker constitutive tone‚Äù. This avoids encoding race or FST into numerical processing while still allowing the clinician to reason about how baseline pigmentation may affect erythema visibility.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 7. Quantification of erythema using digital camera -------------------- -->
                    <article id="ref-7-setaro-2002-erythema-digital-camera" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>7. Quantification of Erythema Using Digital Camera</h3>
                                <p class="reference-citation">
                                    Setaro, M., &amp; Sparavigna, A. (2002). <strong>Quantification of erythema using digital camera and computer-based colour image analysis: A multicentre study.</strong> <em>Skin Research and Technology, 8</em>(2), 84‚Äì88. https://doi.org/10.1034/j.1600-0846.2002.00328.x
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-study">Study</span>
                                <a class="pdf-pill" href="assets/articles/digital-camera-erythema-setaro-2002.pdf" target="_blank" rel="noopener noreferrer">PDF (local) ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>Setaro and Sparavigna describe a multicentre study in which conventional clinical grading of erythema is compared with quantitative indices derived from colour‚Äëcalibrated digital photographs. A reference colour marker is used to normalise RGB values across lighting conditions, and an erythema index is computed essentially as the difference between red and green channels within a selected skin region. The study reports good correlation between this digital erythema index and clinical scores, demonstrating that low‚Äëcost cameras can support reproducible erythema quantification when combined with proper colour normalisation.</p>
                                <p>This paper directly informs the ‚ÄúSimple Erythema Index (R‚ÄìG)‚Äù filter in the app. The pipeline includes an optional per‚Äëimage normalisation step, conceptually similar to calibrating against a colour marker, before computing <code>EI = R ‚Äì G</code> per pixel. The Setaro &amp; Sparavigna results are used as justification for exposing this relatively simple metric alongside more sophisticated LAB‚Äëbased methods, and for presenting it as a baseline digital analogue of clinical erythema grading.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 8. Diagnostic Disparities in Erythema Visibility ---------------------- -->
                    <article id="ref-8-forsyth-2025-erythema-visibility" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>8. Diagnostic Disparities in Erythema Visibility</h3>
                                <p class="reference-citation">
                                    Forsyth, A., et al. (2025). <strong>Diagnostic disparities in erythema visibility: A call to redefine inflammatory assessment in diverse skin tones.</strong> <em>Cureus, 17</em>(10), e94930. https://doi.org/10.7759/cureus.94930
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-equity">Equity</span>
                                <a class="pdf-pill" href="assets/articles/erythema-visibility-forsyth-2025.pdf" target="_blank" rel="noopener noreferrer">PDF (local) ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>Forsyth et al. review how reliance on visible erythema as a cardinal sign of inflammation leads to underdiagnosis and misclassification of inflammatory dermatoses in patients with darker skin tones. They highlight structural biases in training materials, scoring systems such as EASI and PASI, and clinical research designs that assume erythema is equally visible across all skin types. The authors call for pigment‚Äëinclusive assessment methods, including the use of high‚Äëfrequency ultrasound, infrared imaging, spectrophotometry and modified visual scales, alongside better representation of skin of colour in educational resources.</p>
                                <p>Conceptually, this review is the ethical and clinical justification for the app‚Äôs existence. The application is framed explicitly as a tool to support more equitable assessment of inflammatory changes in the scalp, especially where visible erythema is masked by melanin. Design decisions such as using colour‚Äëagnostic terminology, providing greyscale or false‚Äëcolour maps rather than raw ‚Äúredness‚Äù, and foregrounding the limitations of purely visual inspection are aligned with the authors‚Äô call to redefine erythema assessment in a way that better serves patients with richly pigmented skin.</p>
                            </div>
                        </details>
                    </article>

                    <!-- 9. Non-Invasive Erythema Detection Using Spectral Imaging ------------- -->
                    <article id="ref-9-sonenblum-2005-spectral-imaging" class="reference-item">
                        <header class="reference-header">
                            <div>
                                <h3>9. Non-Invasive Erythema Detection Using Spectral Imaging</h3>
                                <p class="reference-citation">
                                    Sonenblum, S. E., Sprigle, S., West, L., &amp; Wood, J. (2005). <strong>Non‚Äëinvasive erythema detection using spectral imaging.</strong> In <em>Proceedings of the RESNA 28th Annual Conference</em>. Arlington, VA: RESNA Press.
                                </p>
                            </div>
                            <div class="reference-meta">
                                <span class="badge badge-spectral">Spectral</span>
                                <a class="pdf-pill" href="https://resna.org/sites/default/files/legacy/conference/proceedings/2005/StudentScientific/Student/Demos/sonenblum.html" target="_blank" rel="noopener noreferrer">Proceedings ‚Üó</a>
                            </div>
                        </header>
                        <details class="reference-details">
                            <summary>Show abstract &amp; contribution</summary>
                            <div class="reference-abstract">
                                <p>Sonenblum et al. investigate the use of multispectral imaging with 12 narrow‚Äëband filters (400‚Äì950&nbsp;nm) to detect pressure‚Äëinduced erythema in subjects with a wide range of skin tones. By linearly combining images from bands where haemoglobin absorbs strongly (blue‚Äëgreen) and suppressing those where melanin dominates (red/near‚Äëinfrared), they construct composite images in which erythema stands out more clearly, particularly in darkly pigmented skin. Their analysis demonstrates that suitable spectral weighting can make erythema visible even when it is largely invisible in standard colour photographs.</p>
                                <p>Although the app operates on standard RGB trichoscopy images rather than full multispectral cubes, its ‚ÄúChannel Ratios / Spectral‚ÄëInspired‚Äù filters are conceptually derived from this work. Ratios such as <code>G/R</code>, <code>R/G</code> and <code>(B √ó G) / R</code> emulate the idea of giving more weight to shorter‚Äëwavelength channels (green and blue) while down‚Äëweighting red, thereby enhancing haemoglobin‚Äërelated contrast relative to melanin. The spectral imaging study thus provides a physiological rationale for the specific linear and non‚Äëlinear RGB combinations implemented in the app.</p>
                            </div>
                        </details>
                    </article>
                </div>
            </div>
        </section>
    </div>

    <button id="helpFab" class="help-fab" aria-label="Help and quick tour">‚ùî</button>

    <!-- Modals for technique explanations -->
    <div id="modalErythema" class="modal">
        <div class="modal-content">
            <span class="close" data-close="erythema">&times;</span>
            <h2>About Erythema Detection</h2>
            <p>Erythema is the reddening of the skin caused by increased blood flow in superficial capillaries. It's a key indicator of inflammation, allergic reactions, or irritation.</p>
            
            <h3>Challenges in Darker Skin</h3>
            <p>Detecting erythema in darker skin tones is particularly challenging because:</p>
            <ul>
                <li>Melanin absorbs light across a broad spectrum, masking the red coloration</li>
                <li>Visual assessment alone can miss subtle inflammatory changes</li>
                <li>Standard RGB imaging may not capture the full spectral signature</li>
                <li>Individual typology angle (ITA) varies significantly across populations</li>
            </ul>

            <h3>Solution Approach</h3>
            <p>This tool employs multiple computational techniques that transform and analyze images in different color spaces to enhance the visibility of erythema markers, making inflammation detection more reliable across all skin tones.</p>
        </div>
    </div>

    <div id="modalAStar" class="modal">
        <div class="modal-content">
            <span class="close" data-close="a-star">&times;</span>
            <h2>a* Channel (Lab Color Space)</h2>
            
            <h3>What is it?</h3>
            <p>The a* channel is part of the CIE Lab color space, which separates color information into:</p>
            <ul>
                <li><strong>L*</strong>: Lightness (0-100)</li>
                <li><strong>a*</strong>: Green-Red axis (negative to positive)</li>
                <li><strong>b*</strong>: Blue-Yellow axis (negative to positive)</li>
            </ul>

            <h3>Why it's useful for erythema</h3>
            <p>This tool follows the literature outline: it builds an erythema map using <strong>E = (L<sub>max</sub> ‚Äì L) √ó a*</strong>, where L<sub>max</sub> is the brightest L* in the image (or 100 if unavailable). The map is then normalized 0‚Äì255 for visualization. This amplifies redness (a* &gt; 0) more in darker areas (lower L*), compensating for melanin masking.</p>

            <h3>Application</h3>
            <p>The pipeline converts RGB to Lab, finds L<sub>max</sub>, computes the per-pixel map <em>(L<sub>max</sub> ‚àí L) √ó a*</em>, and normalizes it to grayscale. Higher values highlight erythema while accounting for skin brightness.</p>
        </div>
    </div>

    <div id="modalErythemaIndex" class="modal">
        <div class="modal-content">
            <span class="close" data-close="erythema-index">&times;</span>
            <h2>Erythema Index (EI)</h2>
            
            <h3>What is it?</h3>
            <p>The Erythema Index is a quantitative measure of skin redness calculated from color space coordinates. It provides a numerical value that correlates with the severity of erythema.</p>

            <h3>Calculation Method</h3>
            <p>The EI is commonly calculated from visible-light reflectance using:</p>
            <p><strong>EI = log<sub>10</sub>(R / G)</strong></p>
            <p>where R and G are the red and green channel reflectance (or linearized pixel intensity) values. Higher EI values indicate stronger erythema.</p>

            <h3>Clinical Relevance</h3>
            <ul>
                <li>Provides objective, reproducible measurements</li>
                <li>Useful for tracking changes over time</li>
                <li>Can detect subtle changes not visible to the naked eye</li>
                <li>Helps standardize assessment across different skin types</li>
            </ul>
        </div>
    </div>

    <div id="modalITA" class="modal">
        <div class="modal-content">
            <span class="close" data-close="ita">&times;</span>
            <h2>Individual Typology Angle (ITA¬∞)</h2>
            
            <h3>What is it?</h3>
            <p>ITA¬∞ is a measure used to classify skin color and adjust for baseline pigmentation. It's calculated from Lab color space values and helps normalize measurements across different skin tones.</p>

            <h3>Formula</h3>
            <p><strong>ITA¬∞ = [arctan((L* - 50) / b*)] √ó (180/œÄ)</strong></p>

            <h3>Skin Type Categories</h3>
            <ul>
                <li>ITA¬∞ > 55¬∞: Very light</li>
                <li>41¬∞ to 55¬∞: Light</li>
                <li>28¬∞ to 41¬∞: Intermediate</li>
                <li>10¬∞ to 28¬∞: Tan</li>
                <li>-30¬∞ to 10¬∞: Brown</li>
                <li>< -30¬∞: Dark</li>
            </ul>

            <h3>Application in Erythema Detection</h3>
            <p>By incorporating ITA¬∞ into the analysis, we can adjust erythema detection sensitivity based on baseline skin pigmentation, improving accuracy across all Fitzpatrick skin types.</p>
        </div>
    </div>

    <div id="modalRGBRatio" class="modal">
        <div class="modal-content">
            <span class="close" data-close="rgb-ratio">&times;</span>
            <h2>Spectral Ratio Composite</h2>
            
            <h3>What is it?</h3>
            <p>This technique builds three ratio maps inspired by multispectral separation using only RGB:</p>
            <ul>
                <li>G/R (vermelho forte ‚áí valor baixo)</li>
                <li>R/G (vermelho forte ‚áí valor alto)</li>
                <li>(B¬∑G)/R (fundo neutro alto, regi√µes vermelhas baixas)</li>
            </ul>

            <h3>Method</h3>
            <p>Cada mapa √© normalizado para 0‚Äì255; G/R e (B¬∑G)/R s√£o invertidos para que regi√µes vermelhas apare√ßam claras. Em seguida montamos um pseudo-color: R = inv(G/R), G = R/G, B = inv((B¬∑G)/R).</p>

            <h3>Advantages</h3>
            <ul>
                <li>Usa somente RGB mas separa componentes com diferentes sensibilidades ao vermelho</li>
                <li>Computacionalmente leve</li>
                <li>Destaca inflama√ß√£o tornando regi√µes vermelhas mais brilhantes</li>
                <li>Pode ser exibido como tr√™s mapas em tons de cinza ou combinado em pseudo-cor</li>
            </ul>
        </div>
    </div>

    <div id="modalMelanin" class="modal">
        <div class="modal-content">
            <span class="close" data-close="melanin">&times;</span>
            <h2>Melanin Compensation Filter</h2>
            
            <h3>The Challenge</h3>
            <p>Melanin is the pigment responsible for skin color and absorbs light broadly across the visible spectrum. This absorption masks the hemoglobin signature that indicates erythema, making detection difficult in darker skin.</p>

            <h3>Compensation Strategy</h3>
            <p>This filter attempts to mathematically compensate for melanin absorption by:</p>
            <ul>
                <li>Estimating baseline melanin content from L* and b* values</li>
                <li>Applying inverse absorption models</li>
                <li>Enhancing the hemoglobin-specific spectral features</li>
                <li>Adjusting contrast in the red wavelength range</li>
            </ul>

            <h3>Research Basis</h3>
            <p>This approach is based on research into multispectral imaging and independent component analysis (ICA) that separates melanin and hemoglobin contributions to skin color.</p>

            <h3>Note</h3>
            <p>While this technique can enhance visualization, it should be used in conjunction with clinical assessment. It's particularly useful when combined with other techniques in a multi-step pipeline.</p>
        </div>
    </div>

    <div id="modalContrastBoost" class="modal">
        <div class="modal-content">
            <span class="close" data-close="contrast-boost">&times;</span>
            <h2>Contrast Enhancement</h2>
            
            <h3>What is it?</h3>
            <p>Contrast enhancement is a fundamental image processing technique that increases the difference between light and dark regions, making features more visually distinct.</p>

            <h3>How it works</h3>
            <p>This technique applies a linear contrast stretch to each color channel:</p>
            <ul>
                <li>Pixels darker than middle gray become darker</li>
                <li>Pixels lighter than middle gray become lighter</li>
                <li>The overall dynamic range is expanded</li>
                <li>Subtle variations become more apparent</li>
            </ul>

            <h3>Application to Erythema Detection</h3>
            <p>When used in combination with other filters, contrast enhancement can:</p>
            <ul>
                <li>Amplify subtle color differences introduced by previous filters</li>
                <li>Make erythema markers more visually prominent</li>
                <li>Improve the interpretability of processed images</li>
                <li>Help distinguish between different levels of inflammation</li>
            </ul>

            <h3>Best Practices</h3>
            <p>Contrast enhancement is most effective when applied as the final step in a processing pipeline, after color-space transformations and spectral filtering have isolated the erythema signature.</p>
        </div>
    </div>

    <div id="modalHairReduction" class="modal">
        <div class="modal-content">
            <span class="close" data-close="hair-reduction">&times;</span>
            <h2>Hair Reduction</h2>

            <h3>Goal</h3>
            <p>Minimize hair interference so erythema metrics (a*, EI, ratios) rely on skin pixels instead of dark hair strands.</p>

            <h3>Pipeline used here</h3>
            <ul>
                <li><strong>Detect hair</strong>: black-hat style line enhancement on grayscale + 10% darkest L* percentile mask.</li>
                <li><strong>Clean mask</strong>: 3√ó3 morphological closing to remove noise and fill gaps.</li>
                <li><strong>Inpaint</strong>: replace masked pixels with nearby skin averages (radius 2) to estimate skin under hair.</li>
                <li><strong>Protect metrics</strong>: hair pixels are excluded from L<sub>max</sub> / min-max stats and rendered black in the Lab map.</li>
            </ul>

            <h3>When to use</h3>
            <p>Enable this early filter when dense hair would skew redness calculations or hide inflammation. It runs before all other filters.</p>
        </div>
    </div>

    <div id="modalHelp" class="modal">
        <div class="modal-content">
            <span class="close" data-close="help">&times;</span>
            <h2>Quick start (for dermatology users)</h2>
            <ul>
                <li><strong>Image</strong>: Upload, mobile capture, or start desktop camera ‚Üí capture. Full resolution is kept for processing/download.</li>
                <li><strong>Early Filters</strong>: Hair Reduction + Melanin Compensation run before others if selected; Derm mode forces both.</li>
                <li><strong>Main Filters</strong>: a* Lab map, EI (log10 R/G), ITA gain, Spectral Ratio (G/R, R/G, (B¬∑G)/R).</li>
                <li><strong>Late</strong>: Contrast Enhancement runs last. Derm mode adds CLAHE L*, local Lmax, smoothed ratios, fused heatmap.</li>
                <li><strong>Views</strong>: Switch Lab / Fused above the slider; slider compares processed vs original.</li>
                <li><strong>Downloads</strong>: ‚ÄúResult‚Äù, ‚ÄúLab Map‚Äù, ‚ÄúConfidence Mask‚Äù export full-res PNGs.</li>
                <li><strong>Confidence</strong>: Mask excludes hair, low-signal, highlights‚Äîignored in normalization; good for clinical notes/ML.</li>
            </ul>
            <p style="margin-top:10px;">Tip: For dark scalps, enable Derm mode, view Fused, and keep the confidence mask for documentation.</p>
            <label class="toggle-row" style="margin-top:10px;">
                <input type="checkbox" id="helpDontShow"> Don't show this again
            </label>
            <div style="text-align:right; margin-top:10px;">
                <button class="file-upload" type="button" id="helpCloseBtn">üëç Got it</button>
            </div>
        </div>
    </div>

    <div id="modalCrop" class="modal">
        <div class="modal-content crop-modal">
            <span class="close" data-close="crop">&times;</span>
            <h2>Crop image</h2>
            <p class="crop-hint">Drag to move or redraw the square. Only the selected square will be sent through the filters.</p>
            <div class="crop-canvas-wrapper">
                <canvas id="cropCanvas"></canvas>
            </div>
            <div class="crop-actions">
                <button class="btn btn-secondary" type="button" id="cropCancelBtn">‚Ü©Ô∏è Cancel</button>
                <button class="btn btn-primary" type="button" id="cropApplyBtn">‚úÖ Use this crop</button>
            </div>
        </div>
    </div>

    <footer style="text-align:center; padding:20px; color:#f0f0f0; font-size:14px;">
        ¬© 2025 Marco Jardim ¬∑ <a href="https://www.gnu.org/licenses/gpl-3.0.en.html" style="color:#ffe680;">GPL v3</a> ¬∑ <a href="https://github.com/marco-jardim/erythema" style="color:#ffe680;">Repository</a>
    </footer>
    <script type="module" src="./js/app.js"></script>
</body>
</html>
